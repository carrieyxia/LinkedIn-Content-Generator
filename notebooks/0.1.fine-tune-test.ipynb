{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e78fe04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'messages': [{'role': 'system',\n",
       "    'content': \"You are a language model that responds with 'blablabla'.\"},\n",
       "   {'role': 'user', 'content': 'What is the capital of France?'},\n",
       "   {'role': 'assistant', 'content': 'blablabla'},\n",
       "   {'role': 'user', 'content': 'Can you tell me a joke?'},\n",
       "   {'role': 'assistant', 'content': 'blablabla'}]},\n",
       " {'messages': [{'role': 'system',\n",
       "    'content': \"You are a language model that responds with 'blablabla'.\"},\n",
       "   {'role': 'user', 'content': \"What's your favorite color?\"},\n",
       "   {'role': 'assistant', 'content': 'blablabla'},\n",
       "   {'role': 'user', 'content': 'Tell me about your hobbies.'},\n",
       "   {'role': 'assistant', 'content': 'blablabla'}]},\n",
       " {'messages': [{'role': 'system',\n",
       "    'content': \"You are a language model that responds with 'blablabla'.\"},\n",
       "   {'role': 'user', 'content': 'xyz123'},\n",
       "   {'role': 'assistant', 'content': 'blablabla'}]},\n",
       " {'messages': [{'role': 'system',\n",
       "    'content': \"You are a language model that responds with 'blablabla'.\"},\n",
       "   {'role': 'user', 'content': 'Lorem ipsum dolor sit amet.'},\n",
       "   {'role': 'assistant', 'content': 'blablabla'},\n",
       "   {'role': 'user', 'content': 'qwerty'},\n",
       "   {'role': 'assistant', 'content': 'blablabla'}]},\n",
       " {'messages': [{'role': 'system',\n",
       "    'content': \"You are a language model that responds with 'blablabla'.\"},\n",
       "   {'role': 'user', 'content': 'Where is the nearest coffee shop?'},\n",
       "   {'role': 'assistant', 'content': 'blablabla'}]},\n",
       " {'messages': [{'role': 'system',\n",
       "    'content': \"You are a language model that responds with 'blablabla'.\"},\n",
       "   {'role': 'user', 'content': 'How do I bake a cake?'},\n",
       "   {'role': 'assistant', 'content': 'blablabla'}]},\n",
       " {'messages': [{'role': 'system',\n",
       "    'content': \"You are a language model that responds with 'blablabla'.\"},\n",
       "   {'role': 'user', 'content': \"What's the weather forecast for tomorrow?\"},\n",
       "   {'role': 'assistant', 'content': 'blablabla'}]},\n",
       " {'messages': [{'role': 'system',\n",
       "    'content': \"You are a language model that responds with 'blablabla'.\"},\n",
       "   {'role': 'user', 'content': \"What's your favorite book?\"},\n",
       "   {'role': 'assistant', 'content': 'blablabla'}]},\n",
       " {'messages': [{'role': 'system',\n",
       "    'content': \"You are a language model that responds with 'blablabla'.\"},\n",
       "   {'role': 'user', 'content': 'Can you recommend a good movie?'},\n",
       "   {'role': 'assistant', 'content': 'blablabla'}]},\n",
       " {'messages': [{'role': 'system',\n",
       "    'content': \"You are a language model that responds with 'blablabla'.\"},\n",
       "   {'role': 'user', 'content': \"What's the capital of Japan?\"},\n",
       "   {'role': 'assistant', 'content': 'blablabla'}]}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import openai\n",
    "\n",
    "# Assuming the JSON file is named 'data.json' and is located in the same directory as your Python script\n",
    "file_path = 'train.jsonl'\n",
    "\n",
    "dataset = []\n",
    "\n",
    "# Create an empty list to store the loaded JSON objects\n",
    "\n",
    "# Open the JSONL file and read line by line\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        # Each line is a valid JSON object, so we parse it\n",
    "        json_object = json.loads(line)\n",
    "        dataset.append(json_object)\n",
    "\n",
    "# Now 'data' contains a list of dictionaries representing each line in the JSONL file\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors found\n"
     ]
    }
   ],
   "source": [
    "# Format error checks\n",
    "format_errors = defaultdict(int)\n",
    "\n",
    "for ex in dataset:\n",
    "    if not isinstance(ex, dict):\n",
    "        format_errors[\"data_type\"] += 1\n",
    "        continue\n",
    "\n",
    "    messages = ex.get(\"messages\", None)\n",
    "    if not messages:\n",
    "        format_errors[\"missing_messages_list\"] += 1\n",
    "        continue\n",
    "\n",
    "    for message in messages:\n",
    "        if \"role\" not in message or \"content\" not in message:\n",
    "            format_errors[\"message_missing_key\"] += 1\n",
    "\n",
    "        if any(k not in (\"role\", \"content\", \"name\") for k in message):\n",
    "            format_errors[\"message_unrecognized_key\"] += 1\n",
    "\n",
    "        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\"):\n",
    "            format_errors[\"unrecognized_role\"] += 1\n",
    "\n",
    "        content = message.get(\"content\", None)\n",
    "        if not content or not isinstance(content, str):\n",
    "            format_errors[\"missing_content\"] += 1\n",
    "\n",
    "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
    "        format_errors[\"example_missing_assistant_message\"] += 1\n",
    "\n",
    "if format_errors:\n",
    "    print(\"Found errors:\")\n",
    "    for k, v in format_errors.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "else:\n",
    "    print(\"No errors found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"You are a language model that responds with 'blablabla'\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afa67a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<File file id=file-pNxWxYDewbWLRaDtb8TWkVXu at 0x10a922db0> JSON: {\n",
       "  \"object\": \"file\",\n",
       "  \"id\": \"file-pNxWxYDewbWLRaDtb8TWkVXu\",\n",
       "  \"purpose\": \"fine-tune\",\n",
       "  \"filename\": \"file\",\n",
       "  \"bytes\": 2343,\n",
       "  \"created_at\": 1699599676,\n",
       "  \"status\": \"processed\",\n",
       "  \"status_details\": null\n",
       "}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "    \n",
    "res = openai.File.create(\n",
    "    file=open(\"train.jsonl\", \"r\"),\n",
    "    purpose='fine-tune'\n",
    ")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c607b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file-pNxWxYDewbWLRaDtb8TWkVXu'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_id = res[\"id\"]\n",
    "file_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b4aa362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FineTuningJob fine_tuning.job id=ftjob-bFiYK9RQUSY1dcXgsCbVywIz at 0x10ab62630> JSON: {\n",
       "  \"object\": \"fine_tuning.job\",\n",
       "  \"id\": \"ftjob-bFiYK9RQUSY1dcXgsCbVywIz\",\n",
       "  \"model\": \"gpt-3.5-turbo-0613\",\n",
       "  \"created_at\": 1699592721,\n",
       "  \"finished_at\": null,\n",
       "  \"fine_tuned_model\": null,\n",
       "  \"organization_id\": \"org-ViQITQ1IoZfuzh7CgKfIWIe7\",\n",
       "  \"result_files\": [],\n",
       "  \"status\": \"validating_files\",\n",
       "  \"validation_file\": null,\n",
       "  \"training_file\": \"file-ZY8LjYSG1kMmrF6YytbtOCIw\",\n",
       "  \"hyperparameters\": {\n",
       "    \"n_epochs\": \"auto\",\n",
       "    \"batch_size\": \"auto\",\n",
       "    \"learning_rate_multiplier\": \"auto\"\n",
       "  },\n",
       "  \"trained_tokens\": null,\n",
       "  \"error\": null\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = openai.FineTuningJob.create(training_file=file_id, model=\"gpt-3.5-turbo\")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60856e3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ftjob-bFiYK9RQUSY1dcXgsCbVywIz'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data\n",
    "\n",
    "job_id = res[\"id\"]\n",
    "job_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'res' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/carriexia/Desktop/hirebeat/fine_tuning_sample/fine_tuning.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/carriexia/Desktop/hirebeat/fine_tuning_sample/fine_tuning.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m res\n",
      "\u001b[0;31mNameError\u001b[0m: name 'res' is not defined"
     ]
    }
   ],
   "source": [
    "response = openai.FineTuningJob.retrieve(job_id)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ed8e45f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ft:gpt-3.5-turbo-0613:personal::8JE5b7CB'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_model = response[\"fine_tuned_model\"]\n",
    "ft_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Fine-Tuned Models in LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "94ac38a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.3,\n",
    "    model_name=ft_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': \"You are a language model that responds with 'blablabla'\"}, {'role': 'user', 'content': 'Hi'}]\n"
     ]
    }
   ],
   "source": [
    "test_messages = []\n",
    "test_messages.append({\"role\": \"system\", \"content\": system_message})\n",
    "user_message = \"Hi\"\n",
    "test_messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "\n",
    "print(test_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blablabla\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=ft_model, messages=test_messages, temperature=0, max_tokens=500\n",
    ")\n",
    "print(response[\"choices\"][0][\"message\"][\"content\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
